{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Uni/211/495/deepnlpdataset\\Sheet_1.csv\n",
      "D:/Uni/211/495/deepnlpdataset\\Sheet_2.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('D:/Uni/211/495/deepnlpdataset'): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id        class                                      response_text  \\\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict   \n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...   \n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...   \n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...   \n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th...   \n",
       "\n",
       "  Unnamed: 3  Unnamed: 4 Unnamed: 5  Unnamed: 6 Unnamed: 7  \n",
       "0        NaN         NaN        NaN         NaN        NaN  \n",
       "1        NaN         NaN        NaN         NaN        NaN  \n",
       "2        NaN         NaN        NaN         NaN        NaN  \n",
       "3        NaN         NaN        NaN         NaN        NaN  \n",
       "4                    NaN        NaN         NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Data\n",
    "df1=pd.read_csv(\"D:/Uni/211/495/deepnlpdataset/Sheet_1.csv\",encoding='latin-1')\n",
    "df2=pd.read_csv(\"D:/Uni/211/495/deepnlpdataset/Sheet_2.csv\",encoding='latin-1')\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id    Sentiment                                             Labels\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict\n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...\n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...\n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...\n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.drop([\"Unnamed: 3\", \"Unnamed: 4\", \"Unnamed: 5\", \"Unnamed: 6\",\"Unnamed: 7\"], axis = 1)\n",
    "df1 = df1.rename(columns={\"class\":\"Sentiment\", \"response_text\":\"Labels\"})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>\\rCustomer Service Supervisor/Tier - Isabella ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>\\rEngineer / Scientist - IBM Microelectronics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>\\rLTS Software Engineer Computational Lithogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>TUTOR\\rWilliston VT - Email me on Indeed: ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flagged</td>\n",
       "      <td>\\rIndependent Consultant - Self-employed\\rBurl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment                                             Labels\n",
       "0  not_flagged  \\rCustomer Service Supervisor/Tier - Isabella ...\n",
       "1  not_flagged  \\rEngineer / Scientist - IBM Microelectronics ...\n",
       "2  not_flagged  \\rLTS Software Engineer Computational Lithogra...\n",
       "3  not_flagged   TUTOR\\rWilliston VT - Email me on Indeed: ind...\n",
       "4      flagged  \\rIndependent Consultant - Self-employed\\rBurl..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop([\"resume_id\"], axis = 1)\n",
    "df2 = df2.rename(columns={\"class\":\"Sentiment\", \"resume_text\":\"Labels\"})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id    Sentiment                                             Labels\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict\n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...\n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...\n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...\n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df  = pd.concat([df1,df2])\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>0</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>1</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>1</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>0</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>0</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id  Sentiment                                             Labels\n",
       "0  response_1          0              I try and avoid this sort of conflict\n",
       "1  response_2          1  Had a friend open up to me about his mental ad...\n",
       "2  response_3          1  I saved a girl from suicide once. She was goin...\n",
       "3  response_4          0  i cant think of one really...i think i may hav...\n",
       "4  response_5          0  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.replace(('flagged','not_flagged'),(1,0),inplace=True)\n",
    "\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentences=combine_df['Labels'].tolist()\n",
    "labels=combine_df['Sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the sentences and labels into training and test sets\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "# Make labels into numpy arrays for use with the network later\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 100)           30000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 606       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 30,613\n",
      "Trainable params: 30,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 300\n",
    "embedding_dim = 100\n",
    "max_length = 25\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 1s 26ms/step - loss: 0.6894 - accuracy: 0.6159 - val_loss: 0.6842 - val_accuracy: 0.7317\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.7134 - val_loss: 0.6703 - val_accuracy: 0.7317\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7134 - val_loss: 0.6569 - val_accuracy: 0.7317\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7134 - val_loss: 0.6446 - val_accuracy: 0.7317\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7134 - val_loss: 0.6328 - val_accuracy: 0.7317\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.7134 - val_loss: 0.6216 - val_accuracy: 0.7317\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7134 - val_loss: 0.6127 - val_accuracy: 0.7317\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7134 - val_loss: 0.6038 - val_accuracy: 0.7317\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7134 - val_loss: 0.5972 - val_accuracy: 0.7317\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7134 - val_loss: 0.5911 - val_accuracy: 0.7317\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7134 - val_loss: 0.5866 - val_accuracy: 0.7317\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7134 - val_loss: 0.5830 - val_accuracy: 0.7317\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7134 - val_loss: 0.5799 - val_accuracy: 0.7317\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7134 - val_loss: 0.5785 - val_accuracy: 0.7317\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7134 - val_loss: 0.5779 - val_accuracy: 0.7317\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7134 - val_loss: 0.5772 - val_accuracy: 0.7317\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7134 - val_loss: 0.5767 - val_accuracy: 0.7317\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7134 - val_loss: 0.5764 - val_accuracy: 0.7317\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7134 - val_loss: 0.5758 - val_accuracy: 0.7317\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7134 - val_loss: 0.5758 - val_accuracy: 0.7317\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7134 - val_loss: 0.5759 - val_accuracy: 0.7317\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7134 - val_loss: 0.5761 - val_accuracy: 0.7317\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7134 - val_loss: 0.5765 - val_accuracy: 0.7317\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7134 - val_loss: 0.5761 - val_accuracy: 0.7317\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7134 - val_loss: 0.5759 - val_accuracy: 0.7317\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7134 - val_loss: 0.5756 - val_accuracy: 0.7317\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7134 - val_loss: 0.5755 - val_accuracy: 0.7317\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7134 - val_loss: 0.5752 - val_accuracy: 0.7317\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7134 - val_loss: 0.5752 - val_accuracy: 0.7317\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7134 - val_loss: 0.5756 - val_accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 150)           45000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 906       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 45,913\n",
      "Trainable params: 45,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 300\n",
    "embedding_dim = 150\n",
    "max_length = 25\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6960 - accuracy: 0.4329 - val_loss: 0.6868 - val_accuracy: 0.7317\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.7134 - val_loss: 0.6802 - val_accuracy: 0.7317\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.7134 - val_loss: 0.6744 - val_accuracy: 0.7317\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7134 - val_loss: 0.6677 - val_accuracy: 0.7317\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.7134 - val_loss: 0.6605 - val_accuracy: 0.7317\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.7134 - val_loss: 0.6528 - val_accuracy: 0.7317\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.7134 - val_loss: 0.6436 - val_accuracy: 0.7317\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7134 - val_loss: 0.6354 - val_accuracy: 0.7317\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7134 - val_loss: 0.6284 - val_accuracy: 0.7317\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.7134 - val_loss: 0.6194 - val_accuracy: 0.7317\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7134 - val_loss: 0.6115 - val_accuracy: 0.7317\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7134 - val_loss: 0.6055 - val_accuracy: 0.7317\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7134 - val_loss: 0.5987 - val_accuracy: 0.7317\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7134 - val_loss: 0.5941 - val_accuracy: 0.7317\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.7134 - val_loss: 0.5904 - val_accuracy: 0.7317\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7134 - val_loss: 0.5859 - val_accuracy: 0.7317\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7134 - val_loss: 0.5823 - val_accuracy: 0.7317\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7134 - val_loss: 0.5812 - val_accuracy: 0.7317\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7134 - val_loss: 0.5805 - val_accuracy: 0.7317\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7134 - val_loss: 0.5788 - val_accuracy: 0.7317\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7134 - val_loss: 0.5785 - val_accuracy: 0.7317\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7134 - val_loss: 0.5775 - val_accuracy: 0.7317\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7134 - val_loss: 0.5769 - val_accuracy: 0.7317\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7134 - val_loss: 0.5769 - val_accuracy: 0.7317\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7134 - val_loss: 0.5768 - val_accuracy: 0.7317\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7134 - val_loss: 0.5768 - val_accuracy: 0.7317\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7134 - val_loss: 0.5769 - val_accuracy: 0.7317\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7195 - val_loss: 0.5769 - val_accuracy: 0.7317\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7195 - val_loss: 0.5764 - val_accuracy: 0.7317\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7317 - val_loss: 0.5770 - val_accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 25, 200)           60000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1206      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 61,213\n",
      "Trainable params: 61,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 300\n",
    "embedding_dim = 200\n",
    "max_length = 25\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 1s 22ms/step - loss: 0.6885 - accuracy: 0.6524 - val_loss: 0.6849 - val_accuracy: 0.7317\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7134 - val_loss: 0.6718 - val_accuracy: 0.7317\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7134 - val_loss: 0.6598 - val_accuracy: 0.7317\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.7134 - val_loss: 0.6472 - val_accuracy: 0.7317\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.7134 - val_loss: 0.6332 - val_accuracy: 0.7317\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.7134 - val_loss: 0.6211 - val_accuracy: 0.7317\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.7134 - val_loss: 0.6098 - val_accuracy: 0.7317\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7134 - val_loss: 0.6027 - val_accuracy: 0.7317\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7134 - val_loss: 0.5968 - val_accuracy: 0.7317\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7134 - val_loss: 0.5895 - val_accuracy: 0.7317\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7134 - val_loss: 0.5846 - val_accuracy: 0.7317\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7134 - val_loss: 0.5793 - val_accuracy: 0.7317\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7134 - val_loss: 0.5768 - val_accuracy: 0.7317\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7134 - val_loss: 0.5755 - val_accuracy: 0.7317\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7134 - val_loss: 0.5748 - val_accuracy: 0.7317\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7134 - val_loss: 0.5744 - val_accuracy: 0.7317\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7134 - val_loss: 0.5743 - val_accuracy: 0.7317\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7134 - val_loss: 0.5740 - val_accuracy: 0.7317\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7134 - val_loss: 0.5736 - val_accuracy: 0.7317\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7134 - val_loss: 0.5734 - val_accuracy: 0.7317\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7134 - val_loss: 0.5731 - val_accuracy: 0.7317\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7134 - val_loss: 0.5729 - val_accuracy: 0.7317\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7134 - val_loss: 0.5725 - val_accuracy: 0.7317\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7134 - val_loss: 0.5721 - val_accuracy: 0.7317\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7134 - val_loss: 0.5719 - val_accuracy: 0.7317\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7134 - val_loss: 0.5724 - val_accuracy: 0.7317\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7134 - val_loss: 0.5728 - val_accuracy: 0.7317\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7134 - val_loss: 0.5724 - val_accuracy: 0.7317\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7439 - val_loss: 0.5734 - val_accuracy: 0.7317\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7561 - val_loss: 0.5728 - val_accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 25, 200)           60000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 130)               172120    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 786       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 232,913\n",
      "Trainable params: 232,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 300\n",
    "embedding_dim = 200\n",
    "max_length = 25\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.LSTM(130),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 87ms/step - loss: 0.6523 - accuracy: 0.7256 - val_loss: 0.6000 - val_accuracy: 0.7317\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5996 - accuracy: 0.7134 - val_loss: 0.5800 - val_accuracy: 0.7317\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5672 - accuracy: 0.7134 - val_loss: 0.5960 - val_accuracy: 0.7317\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5662 - accuracy: 0.7134 - val_loss: 0.6076 - val_accuracy: 0.7317\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5491 - accuracy: 0.7134 - val_loss: 0.5747 - val_accuracy: 0.7317\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5302 - accuracy: 0.7134 - val_loss: 0.5794 - val_accuracy: 0.7317\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5007 - accuracy: 0.7134 - val_loss: 0.5810 - val_accuracy: 0.7317\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4934 - accuracy: 0.7195 - val_loss: 0.5767 - val_accuracy: 0.7317\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4556 - accuracy: 0.7256 - val_loss: 0.6265 - val_accuracy: 0.7317\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4048 - accuracy: 0.8171 - val_loss: 0.5935 - val_accuracy: 0.7317\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3689 - accuracy: 0.8963 - val_loss: 0.7262 - val_accuracy: 0.7317\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3428 - accuracy: 0.8902 - val_loss: 0.6600 - val_accuracy: 0.7561\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2987 - accuracy: 0.9329 - val_loss: 1.0783 - val_accuracy: 0.7317\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3257 - accuracy: 0.8902 - val_loss: 0.6722 - val_accuracy: 0.6585\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2755 - accuracy: 0.9451 - val_loss: 1.1472 - val_accuracy: 0.7317\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3037 - accuracy: 0.8902 - val_loss: 0.8146 - val_accuracy: 0.3659\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.8476 - val_loss: 0.5872 - val_accuracy: 0.7561\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2496 - accuracy: 0.9207 - val_loss: 0.6932 - val_accuracy: 0.7561\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2501 - accuracy: 0.9085 - val_loss: 0.8709 - val_accuracy: 0.7317\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2100 - accuracy: 0.9207 - val_loss: 0.8408 - val_accuracy: 0.7317\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1794 - accuracy: 0.9390 - val_loss: 0.7629 - val_accuracy: 0.7561\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1660 - accuracy: 0.9573 - val_loss: 0.8218 - val_accuracy: 0.6829\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1658 - accuracy: 0.9451 - val_loss: 0.9034 - val_accuracy: 0.6829\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1405 - accuracy: 0.9512 - val_loss: 0.9129 - val_accuracy: 0.6829\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1614 - accuracy: 0.9451 - val_loss: 0.9410 - val_accuracy: 0.5854\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1655 - accuracy: 0.9390 - val_loss: 1.4025 - val_accuracy: 0.7317\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1549 - accuracy: 0.9329 - val_loss: 0.7386 - val_accuracy: 0.5122\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2011 - accuracy: 0.9329 - val_loss: 0.7989 - val_accuracy: 0.5610\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2091 - accuracy: 0.9207 - val_loss: 0.8152 - val_accuracy: 0.6098\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1257 - accuracy: 0.9573 - val_loss: 1.0865 - val_accuracy: 0.7561\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 25, 250)           75000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 130)               198120    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 786       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 273,913\n",
      "Trainable params: 273,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 300\n",
    "embedding_dim = 250\n",
    "max_length = 25\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.LSTM(130),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 119ms/step - loss: 0.6652 - accuracy: 0.6402 - val_loss: 0.6182 - val_accuracy: 0.7317\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6095 - accuracy: 0.7134 - val_loss: 0.5805 - val_accuracy: 0.7317\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5734 - accuracy: 0.7134 - val_loss: 0.5805 - val_accuracy: 0.7317\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5616 - accuracy: 0.7134 - val_loss: 0.5909 - val_accuracy: 0.7317\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5509 - accuracy: 0.7134 - val_loss: 0.5902 - val_accuracy: 0.7317\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5256 - accuracy: 0.7256 - val_loss: 0.5886 - val_accuracy: 0.7317\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4863 - accuracy: 0.7378 - val_loss: 0.6697 - val_accuracy: 0.7317\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4542 - accuracy: 0.8049 - val_loss: 0.7523 - val_accuracy: 0.7317\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.8232 - val_loss: 0.7182 - val_accuracy: 0.5366\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4171 - accuracy: 0.8110 - val_loss: 0.5924 - val_accuracy: 0.7805\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3534 - accuracy: 0.8598 - val_loss: 0.5958 - val_accuracy: 0.7805\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2990 - accuracy: 0.9024 - val_loss: 0.7158 - val_accuracy: 0.6829\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2647 - accuracy: 0.8963 - val_loss: 0.7010 - val_accuracy: 0.7561\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2344 - accuracy: 0.9329 - val_loss: 0.7614 - val_accuracy: 0.7317\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1994 - accuracy: 0.9573 - val_loss: 1.1160 - val_accuracy: 0.7317\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2469 - accuracy: 0.8902 - val_loss: 0.8775 - val_accuracy: 0.7561\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2343 - accuracy: 0.9024 - val_loss: 0.7101 - val_accuracy: 0.6585\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2176 - accuracy: 0.9451 - val_loss: 0.7391 - val_accuracy: 0.7561\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1520 - accuracy: 0.9573 - val_loss: 1.0012 - val_accuracy: 0.7073\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1791 - accuracy: 0.9329 - val_loss: 0.8430 - val_accuracy: 0.7561\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1750 - accuracy: 0.9268 - val_loss: 0.7120 - val_accuracy: 0.8049\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1476 - accuracy: 0.9695 - val_loss: 0.8890 - val_accuracy: 0.7073\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1363 - accuracy: 0.9634 - val_loss: 1.1406 - val_accuracy: 0.7317\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2455 - accuracy: 0.8963 - val_loss: 0.8091 - val_accuracy: 0.6585\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2374 - accuracy: 0.9085 - val_loss: 0.8314 - val_accuracy: 0.5122\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2149 - accuracy: 0.9390 - val_loss: 0.6625 - val_accuracy: 0.8049\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1497 - accuracy: 0.9390 - val_loss: 0.9417 - val_accuracy: 0.7561\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1458 - accuracy: 0.9512 - val_loss: 0.8954 - val_accuracy: 0.7317\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1041 - accuracy: 0.9756 - val_loss: 0.8553 - val_accuracy: 0.7561\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0957 - accuracy: 0.9817 - val_loss: 0.9321 - val_accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    " \n",
    "data = {'GAP1d_100':0.7378, 'GAP1d_150':0.7744, 'GAP1d_200':0.7805, 'LSTM_200':0.9817, 'LSTM_250':0.9695} \n",
    "courses = list(data.keys()) \n",
    "values = list(data.values()) \n",
    "fig = plt.figure(figsize = (6, 6)) \n",
    "\n",
    "plt.bar(courses, values) \n",
    "\n",
    "plt.xlabel(\"Models\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.title(\"Comparison of accuracy\") \n",
    "plt.savefig(\"Sentence_distribution.jpg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
